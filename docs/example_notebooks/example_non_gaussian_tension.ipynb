{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tension estimate for non-Gaussian distributions\n",
    "\n",
    "Cyrille Doux (<doux@lpsc.in2p3.fr>), Marco Raveri (<marco.raveri@unige.it>)\n",
    "\n",
    "In this notebook we show how to calculate the level of tension between two experiments.\n",
    "\n",
    "In particular we show how to compute the statistical significance of a parameter shift between two experiments, DES Y1 and Planck 18, with the two techniques discussed in \n",
    "[Raveri and Doux (2021), arXiv:2105.03324](https://arxiv.org/abs/2105.03324)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plots inline, and load main getdist plot module and samples class\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "# import libraries:\n",
    "import sys, os\n",
    "sys.path.insert(0,os.path.realpath(os.path.join(os.getcwd(),'../..')))\n",
    "from getdist import plots\n",
    "import getdist\n",
    "getdist.chains.print_load_details = False\n",
    "\n",
    "# import the tensiometer tools that we need:\n",
    "import tensiometer\n",
    "from tensiometer import utilities\n",
    "from tensiometer import mcmc_tension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start importing the relevant samples. \n",
    "The code requires the two chains to be getdist MCSamples objects.\n",
    "Check [GetDist documentation](https://getdist.readthedocs.io/en/latest/) for example codes of how to import or create them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the samples (remove no burn in since the example chains have already been cleaned):\n",
    "chains_dir = './../../test_chains/'\n",
    "# the Planck 2018 TTTEEE chain:\n",
    "chain_1 = getdist.mcsamples.loadMCSamples(file_root=chains_dir+'Planck18TTTEEE', no_cache=True)\n",
    "# the DES Y1 3x2 chain:\n",
    "chain_2 = getdist.mcsamples.loadMCSamples(file_root=chains_dir+'DES', no_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the parameter difference distribution. \n",
    "\n",
    "If we denote $P_1(\\theta_1)$ and $P_2(\\theta_2)$ as the two independent distributions, then, defining $\\Delta\\theta \\equiv \\theta_1 - \\theta_2$ then the distribution of parameter differences, $\\Delta\\theta$ is given by:\n",
    "\n",
    "\\begin{align}\n",
    "P(\\Delta \\theta) = \\int P_1(\\theta)P_2(\\theta - \\Delta\\theta) \\, d\\theta\n",
    "\\end{align}\n",
    "\n",
    "Samples from this distribution can be computed as differences between samples of the two distributions. \n",
    "This usually results in a large number of samples so, by default, we undersample.\n",
    "The boost parameter increases the samples retained, up to $O(n^2)$, and should be set to ensure that we have enough samples for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the difference chain:\n",
    "diff_chain = mcmc_tension.parameter_diff_chain(chain_1, chain_2, boost=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do a sanity check plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = diff_chain.getParamNames().getRunningNames()\n",
    "g = plots.get_subplot_plotter()\n",
    "g.triangle_plot([diff_chain], params=param_names, filled=True, markers={_p:0 for _p in param_names})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks non-Gaussian uh? Let's see below how to cope with this!\n",
    "\n",
    "We need to calculate this integral:\n",
    "\n",
    "\\begin{align}\n",
    "\\Delta \\equiv \\int_{P(\\Delta\\theta) > P(0)} P(\\Delta\\theta) \\, d\\Delta \\theta\n",
    "\\end{align}\n",
    "\n",
    "which gives the probability mass enclosed in the (full-D) iso-contour that touches the value corresponding to zero shift.\n",
    "\n",
    "The main problem of this integral is that we have samples from the parameter difference distribution but we cannot associate a probability value to those samples. \n",
    "There are two ways to cope with this problem, that we outline below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing flow estimate of parameter shifts:\n",
    "\n",
    "The first strategy is to build a normalizing flow model for the parameter difference distribution.\n",
    "We learn from the samples the mapping between parameter spaces that Gaussianizes the distribution. Once this is done we can sample from the learned distribution and compute probability values. The previous integral is then Monte-Carlo integrated.\n",
    "\n",
    "The code provides a helper function, `tensiometer.mcmc_tension.flow_parameter_shift(diff_chain)`, to create the model, train it and compute the shift significance. We show here how to use it and later how to proceed manually.\n",
    "\n",
    "Training the normalizing flow is going to take a little while. This is a good time to take break!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the helper function passes all keyword arguments downstream so we can easily set manually all options\n",
    "kwargs = {\n",
    "          'feedback': 2,  # verbosity level\n",
    "          'pop_size': 1,  # controls the number of flows that are trained. The best one is then selected. Since time to solution scales linearly with pop_size, it is a good idea to set it to 1 for a first run. \n",
    "        }\n",
    "\n",
    "# call the helper function:\n",
    "results, diff_flow = tensiometer.mcmc_tension.flow_parameter_shift(diff_chain,   # parameter difference chain\n",
    "                                      cache_dir=None,  # directory where the trained flow is saved, to save time next time\n",
    "                                      root_name='sprob',  # name of the cached flow (usefull to have several in the same folder)\n",
    "                                      **kwargs\n",
    "                                      )\n",
    "\n",
    "# unpack results:\n",
    "shift_P, shift_hi, shift_low = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shift probability considering all parameters:\\n',\n",
    "      f'   P = {shift_P:.5f} +{shift_hi-shift_P:.5f} -{shift_P-shift_low:.5f}')\n",
    "# turn the result to effective number of sigmas:\n",
    "print(f'    n_sigma = {utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'+{utilities.from_confidence_to_sigma(shift_hi)-utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'-{utilities.from_confidence_to_sigma(shift_P)-utilities.from_confidence_to_sigma(shift_low):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual flow calculation\n",
    "\n",
    "Now we see how to unpack the previous helper function and calculate a tension from scratch.\n",
    "\n",
    "We first create and train the synthetic probability model. Again this is going to take a bit.\n",
    "Normally (not in a tutorial) one would save the flow model to cache to avoid retraining every time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "          'feedback': 1,\n",
    "          'plot_every': 1000,\n",
    "          'pop_size': 1,\n",
    "        }\n",
    "\n",
    "flow = tensiometer.synthetic_probability.synthetic_probability.flow_from_chain(diff_chain,  # parameter difference chain\n",
    "                                                         **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can plot training summaries to make sure training went smoothly:\n",
    "flow.training_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the shift probability:\n",
    "shift_P, shift_low, shift_hi = mcmc_tension.estimate_shift(flow)\n",
    "# print the results:\n",
    "print(f'Shift probability considering all parameters:\\n',\n",
    "      f'   P = {shift_P:.5f} +{shift_hi-shift_P:.5f} -{shift_P-shift_low:.5f}')\n",
    "# turn the result to effective number of sigmas:\n",
    "print(f'    n_sigma = {utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'+{utilities.from_confidence_to_sigma(shift_hi)-utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'-{utilities.from_confidence_to_sigma(shift_P)-utilities.from_confidence_to_sigma(shift_low):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is some variance in the result due to initialization. You can repeat the above calculation some times to evaluate the variance.\n",
    "\n",
    "We can now plot the learned distribution. To do so we draw some samples from the learned distribution and then feed them to getdist plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the flow:\n",
    "N = 10000\n",
    "flow_samples = flow.MCSamples(N)\n",
    "\n",
    "# build Gaussian approximation:\n",
    "gaussian_approx = tensiometer.gaussian_tension.gaussian_approximation(diff_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=['orange', 'dodgerblue', 'k']\n",
    "g = plots.get_subplot_plotter()\n",
    "g.settings.num_plot_contours = 2\n",
    "g.triangle_plot([diff_chain, flow_samples, gaussian_approx], params=param_names,\n",
    "                filled=False, markers={_p:0 for _p in param_names},\n",
    "                colors=colors, diag1d_kwargs={'colors':colors})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the two distributions match astonishingly well, capturing all non-Gaussian feature that we can identify in this plot.\n",
    "\n",
    "If you are interested in more details about normalizing flow modeling of probability distributions check out the synthetic probability tutorial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDE estimate of parameter shifts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first run the KDE algorithm with default settings and high feedback to have a sense of its inner workings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_P, shift_low, shift_hi = mcmc_tension.kde_parameter_shift(diff_chain, feedback=10)\n",
    "\n",
    "# print the results:\n",
    "print(f'Shift probability considering all parameters:\\n',\n",
    "      f'   P = {shift_P:.5f} +{shift_hi-shift_P:.5f} -{shift_P-shift_low:.5f}')\n",
    "# turn the result to effective number of sigmas:\n",
    "print(f'    n_sigma = {utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'+{utilities.from_confidence_to_sigma(shift_hi)-utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'-{utilities.from_confidence_to_sigma(shift_P)-utilities.from_confidence_to_sigma(shift_low):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the algorithm proceeds in two steps, elimination of points that are clearly above the probability of zero shift based on the probability estimate containing just a few nearest points and then brute force polishing of the leftover points. This gets the right answer and takes a fairly reasonable amount of time.\n",
    "\n",
    "You could try to run this cell with method='brute_force' to see the type of performance improvement that this algorithm achieves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One key parameter in the estimate of the KDE shift is the smoothing scale for the pdf.\n",
    "The default choice is the one that minimizes the mean integrated square error (MISE) under assumptions of Gaussianity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_P, shift_low, shift_hi = mcmc_tension.kde_parameter_shift(diff_chain, scale='MISE', feedback=0)\n",
    "\n",
    "# print the results:\n",
    "print(f'Shift probability considering all parameters:\\n',\n",
    "      f'   P = {shift_P:.5f} +{shift_hi-shift_P:.5f} -{shift_P-shift_low:.5f}')\n",
    "# turn the result to effective number of sigmas:\n",
    "print(f'    n_sigma = {utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'+{utilities.from_confidence_to_sigma(shift_hi)-utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'-{utilities.from_confidence_to_sigma(shift_P)-utilities.from_confidence_to_sigma(shift_low):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can try different choices. In particular we could try the asyntotic MISE estimator (AMISE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_P, shift_low, shift_hi = mcmc_tension.kde_parameter_shift(diff_chain, scale='AMISE', feedback=0)\n",
    "\n",
    "# print the results:\n",
    "print(f'Shift probability considering all parameters:\\n',\n",
    "      f'   P = {shift_P:.5f} +{shift_hi-shift_P:.5f} -{shift_P-shift_low:.5f}')\n",
    "# turn the result to effective number of sigmas:\n",
    "print(f'    n_sigma = {utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'+{utilities.from_confidence_to_sigma(shift_hi)-utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'-{utilities.from_confidence_to_sigma(shift_P)-utilities.from_confidence_to_sigma(shift_low):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is slightly undersmoothing and hence resulting in a slightly higher tension.\n",
    "\n",
    "Or we could try the maximum bandwidth that is (by design) oversmoothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_P, shift_low, shift_hi = mcmc_tension.kde_parameter_shift(diff_chain, scale='MAX', feedback=0)\n",
    "\n",
    "# print the results:\n",
    "print(f'Shift probability considering all parameters:\\n',\n",
    "      f'   P = {shift_P:.5f} +{shift_hi-shift_P:.5f} -{shift_P-shift_low:.5f}')\n",
    "# turn the result to effective number of sigmas:\n",
    "print(f'    n_sigma = {utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'+{utilities.from_confidence_to_sigma(shift_hi)-utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'-{utilities.from_confidence_to_sigma(shift_P)-utilities.from_confidence_to_sigma(shift_low):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the MISE smoothing scale achieves a balance between these two. Overestimating the smoothing scale usually results in slightly smaller tensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try the adaptive bandwidth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_P, shift_low, shift_hi = mcmc_tension.kde_parameter_shift(diff_chain, scale='BALL', feedback=0)\n",
    "\n",
    "# print the results:\n",
    "print(f'Shift probability considering all parameters:\\n',\n",
    "      f'   P = {shift_P:.5f} +{shift_hi-shift_P:.5f} -{shift_P-shift_low:.5f}')\n",
    "# turn the result to effective number of sigmas:\n",
    "print(f'    n_sigma = {utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'+{utilities.from_confidence_to_sigma(shift_hi)-utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'-{utilities.from_confidence_to_sigma(shift_P)-utilities.from_confidence_to_sigma(shift_low):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see all results are mostly in agreement with each other and this provides an invaluable cross check of the different calculation techniques.\n",
    "\n",
    "The number of samples used in the calculation can be changed to make sure that everything is converged and makes sense.\n",
    "Since all algorithms work in a fairly straightforward way on a laptop we encourage to always try and compare different outputs to make sure the result is sensible.\n",
    "\n",
    "We now verify that the calculation makes physical sense. We know that a difference between these two results mostly lives in a 2 dimensional parameter space so we can do the calculation there and plot the result.\n",
    "\n",
    "In this case, since we are in two dimensions we can use the fft algorithm that is sensibly faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ['delta_omegam', 'delta_sigma8']\n",
    "shift_P, shift_low, shift_hi = mcmc_tension.kde_parameter_shift_2D_fft(diff_chain, param_names=param_names, feedback=0)\n",
    "\n",
    "# print the results:\n",
    "print(f'Shift probability considering all parameters:\\n',\n",
    "      f'   P = {shift_P:.5f} +{shift_hi-shift_P:.5f} -{shift_P-shift_low:.5f}')\n",
    "# turn the result to effective number of sigmas:\n",
    "print(f'    n_sigma = {utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'+{utilities.from_confidence_to_sigma(shift_hi)-utilities.from_confidence_to_sigma(shift_P):.3f}',\n",
    "      f'-{utilities.from_confidence_to_sigma(shift_P)-utilities.from_confidence_to_sigma(shift_low):.3f}')\n",
    "\n",
    "# triangle plot with the 2D shift probability:\n",
    "g = plots.get_single_plotter()\n",
    "diff_chain.updateSettings({'contours': [0.68, 0.95, shift_P]})\n",
    "g.settings.num_plot_contours = 3\n",
    "g.triangle_plot(diff_chain, param_names, filled=True, markers={name:0. for name in param_names});"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
